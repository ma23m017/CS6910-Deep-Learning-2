{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7999112,"sourceType":"datasetVersion","datasetId":4710248}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing essential libraries\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Hyper-parameters\nnum_epochs = 6\nbatch_size = 32\nlearning_rate = 0.001\n\n# Define data transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to a uniform size\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n])\n\n# Load dataset\ndataset = ImageFolder(root='/kaggle/input/i-naturalist1/inaturalist_12K/train', transform=transform)\n\n# Split dataset into training and validation sets\ntraining_data_size = int(0.8 * len(dataset))\nvalidation_data_size = len(dataset) - training_data_size\ntraining_dataset, validation_dataset = random_split(dataset, [training_data_size, validation_data_size])\n\n# Create data loaders\ntraining_data_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\nvalidation_data_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n\n#classes = dataset.classes\n#print(classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining class for CNN\nclass FlexibleCNN(nn.Module):\n    def __init__(self, num_classes, in_channels=3, conv_filters=[16, 32, 64, 128, 256], \n                 kernel_sizes=[3, 3, 3, 3, 3], pool_sizes=[2, 2, 2, 2, 2], \n                 dense_units=512, activation='ReLU', batch_norm = True, dropout = 0.0):\n        self.conv_filters = conv_filters\n        self.kernel_sizes = kernel_sizes\n        self.pool_sizes = pool_sizes\n        self.dense_units = dense_units\n        self.activation = activation\n        self.batch_norm = batch_norm\n        self.dropout = dropout\n        \n        # Invoking the constructor of the base class\n        super(FlexibleCNN, self).__init__()\n\n        # Convolutional layers\n        self.conv_layers = nn.ModuleList()\n        prev_out_size = 224\n        in_channels = in_channels\n        for out_channels, kernel_size, pool_size in zip(conv_filters, kernel_sizes, pool_sizes):\n            conv_layer = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size),\n                self.get_activation(activation),\n                nn.MaxPool2d(pool_size)\n            )\n            \n            # Making condtion to add the batch norm and dropout\n            if batch_norm:\n                conv_layer.add_module(f\"batch_norm_{out_channels}\", nn.BatchNorm2d(out_channels))\n            if dropout > 0.0:\n                conv_layer.add_module(f\"dropout_{out_channels}\", nn.Dropout2d(dropout))\n            self.conv_layers.append(conv_layer)\n            in_channels = out_channels\n            \n        # Defining function to calculate and return the kernel size dynamically\n        def cal_size(stride, padding, kernel_size, prev_size):\n            new_size = (prev_size-kernel_size+2*padding)/stride + 1\n            return new_size//2\n        \n        prev_size = 224 # Starting with the size 224\n        \n        # Running the loop five times for 5 number of blocks\n        for i in range(5):\n            new_size1 = cal_size(stride = 1, padding = 0, kernel_size = self.kernel_sizes[i], prev_size= prev_size)\n            prev_size = new_size1\n        print(new_size1)\n\n        #fully connected layers\n        #self.fc1 = nn.Linear(conv_filters[-1] * 7 * 7, dense_units)\n        self.fc1 = nn.Linear(self.conv_filters[4] * int(new_size1) * int(new_size1), self.dense_units)\n        self.fc2 = nn.Linear(self.dense_units, 10)#num_classes)\n\n    def forward(self, x):\n        # Forward pass through convolutional layers\n        for conv_layer in self.conv_layers:\n            x = conv_layer(x)\n\n        # Flatten the output for the fully connected layer\n        x = torch.flatten(x, 1)\n\n        # Forward pass through fully connected layers\n        #x = F.relu(self.fc1(x))\n        x = self.get_activation(self.activation)(self.fc1(x))\n        x = self.fc2(x)\n        return x\n    \n    # Defining function to get the different activation functions\n    def get_activation(self, activation):\n        if activation == 'ReLU':\n            return nn.ReLU()\n        elif activation == 'GELU':\n            return nn.GELU()\n        elif activation == 'SiLU':\n            return nn.SiLU()\n        elif activation == 'Mish':\n            return nn.Mish()\n        else:\n            raise ValueError(\"Invalid activation function\")\n            \n#model = FlexibleCNN(10)\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:07:15.760486Z","iopub.execute_input":"2024-04-07T20:07:15.761101Z","iopub.status.idle":"2024-04-07T20:07:15.777452Z","shell.execute_reply.started":"2024-04-07T20:07:15.761067Z","shell.execute_reply":"2024-04-07T20:07:15.776529Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!pip install wandb  #installing wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:07:19.791034Z","iopub.execute_input":"2024-04-07T20:07:19.791392Z","iopub.status.idle":"2024-04-07T20:07:32.012071Z","shell.execute_reply.started":"2024-04-07T20:07:19.791367Z","shell.execute_reply":"2024-04-07T20:07:32.010899Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing wandb and essential libraries\nimport wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:07:44.863504Z","iopub.execute_input":"2024-04-07T20:07:44.864335Z","iopub.status.idle":"2024-04-07T20:07:44.869374Z","shell.execute_reply.started":"2024-04-07T20:07:44.864297Z","shell.execute_reply":"2024-04-07T20:07:44.868355Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"wandb.login(key='cd7a6c2259e8886dc269bbf6f0f9e55089d3beeb')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:07:54.309443Z","iopub.execute_input":"2024-04-07T20:07:54.310252Z","iopub.status.idle":"2024-04-07T20:07:54.402065Z","shell.execute_reply.started":"2024-04-07T20:07:54.310221Z","shell.execute_reply":"2024-04-07T20:07:54.401172Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Defining sweep configuration\nsweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep test23',\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'kernel_size':{\n            'values': [[3,3,3,3,3], [3,5,5,7,7], [7,7,5,5,3]]\n        },\n        'dropout': {\n            'values': [0.2, 0.3]\n        },\n        'activation': {\n            'values': ['ReLU', 'GELU', 'SiLU', 'Mish']\n        },\n        'batch_norm':{\n            'values': [True,False]\n        },\n        'filt_org':{\n            'values': [[32,32,32,32,32],[128,128,64,64,32],[32,64,128,256,512]]\n        },\n        'data_augment': {\n            'values': [False]\n        },\n        'num_dense':{\n            'values': [128, 256]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep=sweep_config, project='Deep_Learning_Assignment2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    '''\n    WandB calls main function each time with differnet combination.\n\n    We can retrive the same and use the same values for our hypermeters.\n\n    '''\n\n\n    with wandb.init(entity = 'prabhat-kumar') as run:\n\n        run_name=\"-act_\"+wandb.config.activation+\"-ks\"+str(wandb.config.kernel_size)+'-nd'+str(wandb.config.num_dense)\n        wandb.run.name=run_name\n#         actv = get_activation(wandb.config.activation)\n        model = FlexibleCNN(num_classes=10, in_channels=3, conv_filters=wandb.config.filt_org, \n                 kernel_sizes=wandb.config.kernel_size, pool_sizes=[2, 2, 2, 2, 2], \n                 dense_units=wandb.config.num_dense, activation=wandb.config.activation).to(device)\n        \n        \n        # Loss and optimizer\n        criterion = nn.CrossEntropyLoss()\n        #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   # Using Adam as an optimizer\n\n        # Training loop\n        for epoch in range(num_epochs):\n            #initializing the necessary values\n            total_training_data = 0\n            correct_predicted_train_data = 0\n            loss1 = 0\n            # Train the model\n            model.train()\n            for images, labels in training_data_loader:\n                # Moving images and labels to GPU\n                images = images.to(device)\n                labels = labels.to(device)\n        \n                # Forward pass\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n        \n                # Backward and optimize\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                loss1 = loss1 + loss.item()\n                \n                # Calculate the training accuracy\n                max_value, predicted_by_model = torch.max(outputs, 1)\n                total_training_data = total_training_data + labels.size(0)\n                correct_predicted_train_data = correct_predicted_train_data + (predicted_by_model == labels).sum().item()\n                \n            train_accuracy = 100*correct_predicted_train_data/total_training_data\n            print(f'Epoch number {epoch+1}, Training Accuracy: {train_accuracy:.2f}%') # Printing training accuracy\n            wandb.log({'train_loss': round(loss1 / len(training_data_loader), 2)})\n            wandb.log({'train_accuracy': round(train_accuracy, 2)})\n\n            #wandb.log({'train_loss':running_loss/len(train_loader)})\n            #wandb.log({'train_accuracy':train_accuracy})\n            \n        \n    \n            # Validate the model\n            model.eval()\n            with torch.no_grad():\n                # Initializing the values\n                correct_predicted_validation_data = 0\n                total_validation_data = 0\n                for images, labels in validation_data_loader:\n                    \n                    images = images.to(device)  # Moving images to GPU\n                    labels = labels.to(device)  # Moving labels to GPU\n            \n                    # Forward pass\n                    outputs = model(images)\n                    max_value, predicted_by_model = torch.max(outputs, 1)\n            \n                    # Compute accuracy\n                    total_validation_data = total_validation_data + labels.size(0)\n                    correct_predicted_validation_data = correct_predicted_validation_data + (predicted_by_model == labels).sum().item()\n            \n        \n                val_accuracy = 100 * correct_predicted_validation_data / total_validation_data\n                print(f'Epoch number {epoch+1}, Validation Accuracy: {val_accuracy:.2f}%')\n                wandb.log({'val_accuracy':val_accuracy})\n                wandb.log({'epoch':epoch+1})\n    \n\n        print('Finished Training') # Here training finished\n\nwandb.agent(sweep_id, function=main,count=1) # calls main function for count number of times.\nwandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing using best hyperparameter","metadata":{}},{"cell_type":"code","source":"# Importing essential libraries\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Hyper-parameters\nnum_epochs = 5\nbatch_size = 32\nlearning_rate = 0.001\n\n# Define data transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to a uniform size\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n])\n\n# Load dataset\ndataset = ImageFolder(root='/kaggle/input/i-naturalist1/inaturalist_12K/train', transform=transform)\n\n# Split dataset into training and validation sets\ntraining_data_size = int(0.8 * len(dataset))\nvalidation_data_size = len(dataset) - training_data_size\ntraining_dataset, validation_dataset = random_split(dataset, [training_data_size, validation_data_size])\n\n# Create data loaders\ntraining_data_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\nvalidation_data_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n\ntesting_dataset = ImageFolder(root='/kaggle/input/i-naturalist1/inaturalist_12K/val', transform=transform)\n\ntesting_data_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=True)\n\n#classes = dataset.classes\n#print(classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:06:41.295112Z","iopub.execute_input":"2024-04-07T20:06:41.296002Z","iopub.status.idle":"2024-04-07T20:06:46.450091Z","shell.execute_reply.started":"2024-04-07T20:06:41.295971Z","shell.execute_reply":"2024-04-07T20:06:46.449305Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep test(test_data)1',\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'kernel_size':{\n            'values': [[3,5,5,7,7]]\n        },\n        'dropout': {\n            'values': [0.3]\n        },\n        'activation': {\n            'values': ['GELU']\n        },\n        'batch_norm':{\n            'values': [False]\n        },\n        'filt_org':{\n            'values': [[32,64,128,256,512]]\n        },\n        'data_augment': {\n            'values': [False]\n        },\n        'num_dense':{\n            'values': [128]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep=sweep_config, project='Deep_Learning_Assignment2')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:08:28.932855Z","iopub.execute_input":"2024-04-07T20:08:28.933792Z","iopub.status.idle":"2024-04-07T20:08:29.161976Z","shell.execute_reply.started":"2024-04-07T20:08:28.933760Z","shell.execute_reply":"2024-04-07T20:08:29.160931Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Create sweep with ID: prcbpb60\nSweep URL: https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/prcbpb60\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    '''\n    WandB calls main function each time with different combinations.\n    We can retrieve the same and use the same values for our hyperparameters.\n    '''\n\n    with wandb.init(entity='prabhat-kumar') as run:\n\n        run_name = \"-act_\" + wandb.config.activation + \"-ks\" + str(wandb.config.kernel_size) + '-nd' + str(\n            wandb.config.num_dense)\n        wandb.run.name = run_name\n\n        model = FlexibleCNN(num_classes=10, in_channels=3, conv_filters=wandb.config.filt_org,\n                            kernel_sizes=wandb.config.kernel_size, pool_sizes=[2, 2, 2, 2, 2],\n                            dense_units=wandb.config.num_dense, activation=wandb.config.activation).to(device)\n\n        # Loss and optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Using Adam as an optimizer\n\n        # Training loop\n        for epoch in range(num_epochs):\n            # initializing the necessary values\n            total_training_data = 0\n            correct_predicted_train_data = 0\n            loss1 = 0\n            # Train the model\n            model.train()\n            for images, labels in training_data_loader:\n                # Moving images and labels to GPU\n                images = images.to(device)\n                labels = labels.to(device)\n\n                # Forward pass\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                # Backward and optimize\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                loss1 = loss1 + loss.item()\n\n                # Calculate the training accuracy\n                max_value, predicted_by_model = torch.max(outputs, 1)\n                total_training_data = total_training_data + labels.size(0)\n                correct_predicted_train_data = correct_predicted_train_data + (\n                            predicted_by_model == labels).sum().item()\n\n            train_accuracy = 100 * correct_predicted_train_data / total_training_data\n            print(f'Epoch number {epoch + 1}, Training Accuracy: {train_accuracy:.2f}%')  # Printing training accuracy\n            wandb.log({'train_loss': round(loss1 / len(training_data_loader), 2)})\n            wandb.log({'train_accuracy': round(train_accuracy, 2)})\n\n            # Validate the model\n            model.eval()\n            with torch.no_grad():\n                # Initializing the values\n                correct_predicted_testing_data = 0\n                total_testing_data = 0\n                class_counter = [0] * 10  # Counter for each class\n\n                for images, labels in testing_data_loader:\n                    images = images.to(device)  # Moving images to GPU\n                    labels = labels.to(device)  # Moving labels to GPU\n\n                    # Forward pass\n                    outputs = model(images)\n                    max_value, predicted_by_model = torch.max(outputs, 1)\n\n                    # Compute accuracy\n                    total_testing_data = total_testing_data + labels.size(0)\n                    correct_predicted_testing_data = correct_predicted_testing_data + (predicted_by_model == labels).sum().item()\n\n                    # Plot images along with their labels and predicted labels\n                    for i in range(len(images)):\n                        #image = images[i].cpu().numpy()\n                        image = images[i].cpu().permute(1, 2, 0).numpy()\n                        label = labels[i].cpu().item()\n                        predicted_label = predicted_by_model[i].cpu().item()\n\n                        # Check if we need to plot this class\n                        if class_counter[label] < 3:\n                            wandb.log({f'Class_{label}_Image_{class_counter[label]}': [wandb.Image(image, caption=f'True: {label}, Predicted: {predicted_label}')]})\n\n                            class_counter[label] = class_counter[label] + 1\n\n                test_accuracy = 100 * correct_predicted_testing_data / total_testing_data\n                print(f'Epoch number {epoch + 1}, Test Accuracy: {test_accuracy:.2f}%')\n                wandb.log({'test_accuracy': test_accuracy})\n                wandb.log({'epoch': epoch + 1})\n\n        print('Finished Training')\n\nwandb.agent(sweep_id, function=main, count=1)  # calls main function for count number of times.\nwandb.finish()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T20:23:05.289733Z","iopub.execute_input":"2024-04-07T20:23:05.290613Z","iopub.status.idle":"2024-04-07T20:35:22.597504Z","shell.execute_reply.started":"2024-04-07T20:23:05.290581Z","shell.execute_reply":"2024-04-07T20:35:22.596655Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qbft0p6b with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilt_org: [32, 64, 128, 256, 512]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: [3, 5, 5, 7, 7]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_202307-qbft0p6b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/qbft0p6b' target=\"_blank\">light-sweep-4</a></strong> to <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/prcbpb60' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/prcbpb60</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/prcbpb60' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/prcbpb60</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/qbft0p6b' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/qbft0p6b</a>"},"metadata":{}},{"name":"stdout","text":"1.0\nEpoch number 1, Training Accuracy: 23.54%\nEpoch number 1, Test Accuracy: 26.80%\nEpoch number 2, Training Accuracy: 28.09%\nEpoch number 2, Test Accuracy: 26.55%\nEpoch number 3, Training Accuracy: 31.79%\nEpoch number 3, Test Accuracy: 31.45%\nEpoch number 4, Training Accuracy: 34.37%\nEpoch number 4, Test Accuracy: 34.60%\nEpoch number 5, Training Accuracy: 37.35%\nEpoch number 5, Test Accuracy: 36.30%\nFinished Training\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='13.495 MB of 13.495 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>test_accuracy</td><td>▁▁▅▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▅▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>test_accuracy</td><td>36.3</td></tr><tr><td>train_accuracy</td><td>37.35</td></tr><tr><td>train_loss</td><td>1.78</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">light-sweep-4</strong> at: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/qbft0p6b' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/qbft0p6b</a><br/>Synced 6 W&B file(s), 150 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_202307-qbft0p6b/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}