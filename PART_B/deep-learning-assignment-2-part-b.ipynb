{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8048329,"sourceType":"datasetVersion","datasetId":4746029}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing essential libraries\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Hyper-parameters\nnum_epochs = 5\nbatch_size = 32\nlearning_rate = 0.001\n\n# Define data transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to a uniform size\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n])\n\n# Load dataset\ndataset = ImageFolder(root='/kaggle/input/inaturalist2/inaturalist_12K/train', transform=transform)\n\n# Split dataset into training and validation sets\ntraining_data_size = int(0.8 * len(dataset))\nvalidation_data_size = len(dataset) - training_data_size\ntraining_dataset, validation_dataset = random_split(dataset, [training_data_size, validation_data_size])\n\n# Create data loaders\ntraining_data_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\nvalidation_data_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n\ntesting_dataset = ImageFolder(root='/kaggle/input/inaturalist2/inaturalist_12K/val', transform=transform)\n\ntesting_data_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=True)\n\n#classes = dataset.classes\n#print(classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T06:43:37.345528Z","iopub.execute_input":"2024-04-08T06:43:37.345906Z","iopub.status.idle":"2024-04-08T06:43:59.192279Z","shell.execute_reply.started":"2024-04-08T06:43:37.345878Z","shell.execute_reply":"2024-04-08T06:43:59.191233Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Defining function to freeze the layers\ndef freeze_layers(model, freeze_percent=0.5):\n    total_layers = len(list(model.parameters()))\n    num_layers_to_freeze = int(total_layers * freeze_percent)\n    layers_frozen = 0\n\n    for name, param in model.named_parameters():\n        if layers_frozen < num_layers_to_freeze:\n            param.requires_grad = False\n            layers_frozen += 1\n        else:\n            break\n'''\n# Load pre-trained ResNet50 model\nmodel = models.resnet50(pretrained=True)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 10)\n\n# Verify if layers are frozen\n\nfor name, param in model.named_parameters():\n    print(name, param.requires_grad)\n    \nprint(model)'''","metadata":{"execution":{"iopub.status.busy":"2024-04-08T06:44:03.139506Z","iopub.execute_input":"2024-04-08T06:44:03.140493Z","iopub.status.idle":"2024-04-08T06:44:03.149516Z","shell.execute_reply.started":"2024-04-08T06:44:03.140448Z","shell.execute_reply":"2024-04-08T06:44:03.148627Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'\\n# Load pre-trained ResNet50 model\\nmodel = models.resnet50(pretrained=True)\\nnum_features = model.fc.in_features\\nmodel.fc = nn.Linear(num_features, 10)\\n\\n# Verify if layers are frozen\\n\\nfor name, param in model.named_parameters():\\n    print(name, param.requires_grad)\\n    \\nprint(model)'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install wandb  # Installing wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-08T06:44:07.813446Z","iopub.execute_input":"2024-04-08T06:44:07.813799Z","iopub.status.idle":"2024-04-08T06:44:22.191261Z","shell.execute_reply.started":"2024-04-08T06:44:07.813772Z","shell.execute_reply":"2024-04-08T06:44:22.190232Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing wandb and essential libraries\n\nimport wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-04-08T06:44:27.306380Z","iopub.execute_input":"2024-04-08T06:44:27.307077Z","iopub.status.idle":"2024-04-08T06:44:28.288356Z","shell.execute_reply.started":"2024-04-08T06:44:27.307042Z","shell.execute_reply":"2024-04-08T06:44:28.287322Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"wandb.login(key='cd7a6c2259e8886dc269bbf6f0f9e55089d3beeb')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T06:44:32.269390Z","iopub.execute_input":"2024-04-08T06:44:32.269748Z","iopub.status.idle":"2024-04-08T06:44:34.201355Z","shell.execute_reply.started":"2024-04-08T06:44:32.269720Z","shell.execute_reply":"2024-04-08T06:44:34.200371Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"#defining the sweep configuration\nsweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep test(check)',\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'freezing' : {\n            'values' : [0.7,0.8,0.9]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep=sweep_config, project='Deep_Learning_Assignment2_PartB')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T06:44:39.978288Z","iopub.execute_input":"2024-04-08T06:44:39.979087Z","iopub.status.idle":"2024-04-08T06:44:51.310991Z","shell.execute_reply.started":"2024-04-08T06:44:39.979056Z","shell.execute_reply":"2024-04-08T06:44:51.309847Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Create sweep with ID: vg8vf67x\nSweep URL: https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/sweeps/vg8vf67x\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    '''\n    WandB calls main function each time with differnet combination.\n\n    We can retrive the same and use the same values for our hypermeters.\n\n    '''\n\n\n    with wandb.init(entity = 'prabhat-kumar') as run:\n\n        run_name=\"-frz\"+str(wandb.config.freezing)\n        wandb.run.name=run_name\n#         actv = get_activation(wandb.config.activation)\n        \n        # Load pre-trained ResNet50 model\n        model = models.resnet50(pretrained=True)\n        \n        num_features = model.fc.in_features\n        model.fc = nn.Linear(num_features, 10)\n        model = model.to(device)\n        \n        freeze_layers(model, freeze_percent=wandb.config.freezing)\n        \n        \n        # Loss and optimizer\n        criterion = nn.CrossEntropyLoss()\n        #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   # Using Adam as an optimizer\n\n        # Training loop\n        for epoch in range(num_epochs):\n            #initializing the necessary values\n            total_training_data = 0\n            correct_predicted_train_data = 0\n            loss1 = 0\n            # Train the model\n            model.train()\n            for images, labels in training_data_loader:\n                # Moving images and labels to GPU\n                images = images.to(device)\n                labels = labels.to(device)\n        \n                # Forward pass\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n        \n                # Backward and optimize\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                loss1 = loss1 + loss.item()\n                \n                # Calculate the training accuracy\n                max_value, predicted_by_model = torch.max(outputs, 1)\n                total_training_data = total_training_data + labels.size(0)\n                correct_predicted_train_data = correct_predicted_train_data + (predicted_by_model == labels).sum().item()\n                \n            train_accuracy = 100*correct_predicted_train_data/total_training_data\n            print(f'Epoch number {epoch+1}, Training Accuracy: {train_accuracy:.2f}%') # Printing training accuracy\n            wandb.log({'train_loss': round(loss1 / len(training_data_loader), 2)})\n            wandb.log({'train_accuracy': round(train_accuracy, 2)})\n\n            #wandb.log({'train_loss':running_loss/len(train_loader)})\n            #wandb.log({'train_accuracy':train_accuracy})\n            \n        \n    \n            # Validate the model\n            model.eval()\n            with torch.no_grad():\n                # Initializing the values\n                correct_predicted_validation_data = 0\n                total_validation_data = 0\n                for images, labels in validation_data_loader:\n                    \n                    images = images.to(device)  # Moving images to GPU\n                    labels = labels.to(device)  # Moving labels to GPU\n            \n                    # Forward pass\n                    outputs = model(images)\n                    max_value, predicted_by_model = torch.max(outputs, 1)\n            \n                    # Compute accuracy\n                    total_validation_data = total_validation_data + labels.size(0)\n                    correct_predicted_validation_data = correct_predicted_validation_data + (predicted_by_model == labels).sum().item()\n            \n        \n                val_accuracy = 100 * correct_predicted_validation_data / total_validation_data\n                print(f'Epoch number {epoch+1}, Validation Accuracy: {val_accuracy:.2f}%')\n                wandb.log({'val_accuracy':val_accuracy})\n                wandb.log({'epoch':epoch+1})\n    \n\n        print('Finished Training') # Here training finished\n\nwandb.agent(sweep_id, function=main,count=1) # calls main function for count number of times.\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T06:45:09.209876Z","iopub.execute_input":"2024-04-08T06:45:09.210670Z","iopub.status.idle":"2024-04-08T07:00:47.292026Z","shell.execute_reply.started":"2024-04-08T06:45:09.210635Z","shell.execute_reply":"2024-04-08T07:00:47.291016Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 37gl0833 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfreezing: 0.7\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprabhat-kumar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240408_064510-37gl0833</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/runs/37gl0833' target=\"_blank\">feasible-sweep-1</a></strong> to <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/sweeps/vg8vf67x' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/sweeps/vg8vf67x</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/sweeps/vg8vf67x' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/sweeps/vg8vf67x</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/runs/37gl0833' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/runs/37gl0833</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 149MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch number 1, Training Accuracy: 57.37%\nEpoch number 1, Validation Accuracy: 61.45%\nEpoch number 2, Training Accuracy: 72.91%\nEpoch number 2, Validation Accuracy: 66.85%\nEpoch number 3, Training Accuracy: 81.70%\nEpoch number 3, Validation Accuracy: 69.95%\nEpoch number 4, Training Accuracy: 88.21%\nEpoch number 4, Validation Accuracy: 67.25%\nEpoch number 5, Training Accuracy: 91.59%\nEpoch number 5, Validation Accuracy: 70.15%\nFinished Training\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅█▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>train_accuracy</td><td>91.59</td></tr><tr><td>train_loss</td><td>0.26</td></tr><tr><td>val_accuracy</td><td>70.15</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">feasible-sweep-1</strong> at: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/runs/37gl0833' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2_PartB/runs/37gl0833</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240408_064510-37gl0833/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}