{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7999112,"sourceType":"datasetVersion","datasetId":4710248}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing essential libraries\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# Hyper-parameters \nnum_epochs = 2\nbatch_size = 32\nlearning_rate = 0.01\n\n# Define data transformation\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to a uniform size\n    transforms.ToTensor(),  # Convert images to PyTorch tensors\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize images\n])\n\n# Load dataset\ndataset = ImageFolder(root='/kaggle/input/i-naturalist1/inaturalist_12K/train', transform=transform)\n\n# Split dataset into training and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\nclasses = dataset.classes\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:55:06.624640Z","iopub.execute_input":"2024-04-04T13:55:06.625177Z","iopub.status.idle":"2024-04-04T13:55:30.670234Z","shell.execute_reply.started":"2024-04-04T13:55:06.625147Z","shell.execute_reply":"2024-04-04T13:55:30.669168Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n","output_type":"stream"}]},{"cell_type":"code","source":"#defining class for CNN\nclass FlexibleCNN(nn.Module):\n    def __init__(self, num_classes, in_channels=3, conv_filters=[16, 32, 64, 128, 256], \n                 kernel_sizes=[3, 3, 3, 3, 3], pool_sizes=[2, 2, 2, 2, 2], \n                 dense_units=512, activation='ReLU'):\n        self.conv_filters = conv_filters\n        self.kernel_sizes = kernel_sizes\n        self.pool_sizes = pool_sizes\n        self.dense_units = dense_units\n        self.activation = activation\n        \n        super(FlexibleCNN, self).__init__()\n\n        #convolutional layers\n        self.conv_layers = nn.ModuleList()\n        prev_out_size = 224\n        in_channels = in_channels\n        for out_channels, kernel_size, pool_size in zip(conv_filters, kernel_sizes, pool_sizes):\n            self.conv_layers.append(\n                nn.Sequential(\n                    nn.Conv2d(in_channels, out_channels, kernel_size),\n                    self.get_activation(activation),\n                    nn.MaxPool2d(pool_size)\n                )\n            )\n            in_channels = out_channels\n            \n        def cal_size(stride, padding, kernel_size, prev_size):\n            new_size = (prev_size-kernel_size+2*padding)/stride + 1\n            return new_size//2\n        prev_size = 224\n        \n        for i in range(5):\n            new_size1 = cal_size(stride = 1, padding = 0, kernel_size = self.kernel_sizes[i], prev_size= prev_size)\n            prev_size = new_size1\n        print(new_size1)\n\n        #fully connected layers\n        #self.fc1 = nn.Linear(conv_filters[-1] * 7 * 7, dense_units)\n        self.fc1 = nn.Linear(self.conv_filters[4] * int(new_size1) * int(new_size1), self.dense_units)\n        self.fc2 = nn.Linear(self.dense_units, 10)#num_classes)\n\n    def forward(self, x):\n        # Forward pass through convolutional layers\n        for conv_layer in self.conv_layers:\n            x = conv_layer(x)\n\n        # Flatten the output for the fully connected layer\n        x = torch.flatten(x, 1)\n\n        # Forward pass through fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n    def get_activation(self, activation):\n        if activation == 'ReLU':\n            return nn.ReLU()\n        elif activation == 'LeakyReLU':\n            return nn.LeakyReLU()\n        elif activation == 'Sigmoid':\n            return nn.Sigmoid()\n        elif activation == 'Tanh':\n            return nn.Tanh()\n        else:\n            raise ValueError(\"Invalid activation function\")\n'''\n# Example usage:\nmodel = FlexibleCNN(num_classes=10, \n                    conv_filters=[32, 64, 128, 256, 512], \n                    kernel_sizes=[3, 3, 3, 3, 3], \n                    pool_sizes=[2, 2, 2, 2, 2], \n                    dense_units=256, \n                    activation='ReLU')\n\n#printing the model summary\nprint(model)'''","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:55:38.028153Z","iopub.execute_input":"2024-04-04T13:55:38.028624Z","iopub.status.idle":"2024-04-04T13:55:38.048650Z","shell.execute_reply.started":"2024-04-04T13:55:38.028594Z","shell.execute_reply":"2024-04-04T13:55:38.047779Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"\"\\n# Example usage:\\nmodel = FlexibleCNN(num_classes=10, \\n                    conv_filters=[32, 64, 128, 256, 512], \\n                    kernel_sizes=[3, 3, 3, 3, 3], \\n                    pool_sizes=[2, 2, 2, 2, 2], \\n                    dense_units=256, \\n                    activation='ReLU')\\n\\n#printing the model summary\\nprint(model)\""},"metadata":{}}]},{"cell_type":"code","source":"def get_activation(activation):\n    if activation == 'ReLU':\n        return nn.ReLU()\n    elif activation == 'LeakyReLU':\n        return nn.LeakyReLU()\n    elif activation == 'Sigmoid':\n        return nn.Sigmoid()\n    elif activation == 'Tanh':\n        return nn.Tanh()\n    else:\n        raise ValueError(\"Invalid activation function\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T10:58:32.076847Z","iopub.execute_input":"2024-04-04T10:58:32.077218Z","iopub.status.idle":"2024-04-04T10:58:32.083272Z","shell.execute_reply.started":"2024-04-04T10:58:32.077189Z","shell.execute_reply":"2024-04-04T10:58:32.082310Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n# Training loop\nfor epoch in range(num_epochs):\n    # Train the model\n    model.train()\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    # Validate the model\n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            # Forward pass\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            \n            # Compute accuracy\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n        val_accuracy = 100 * correct / total\n        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T10:58:35.775892Z","iopub.execute_input":"2024-04-04T10:58:35.776285Z","iopub.status.idle":"2024-04-04T10:58:35.910551Z","shell.execute_reply.started":"2024-04-04T10:58:35.776256Z","shell.execute_reply":"2024-04-04T10:58:35.909277Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loss and optimizer\u001b[39;00m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:55:45.591820Z","iopub.execute_input":"2024-04-04T13:55:45.592676Z","iopub.status.idle":"2024-04-04T13:56:00.305582Z","shell.execute_reply.started":"2024-04-04T13:55:45.592643Z","shell.execute_reply":"2024-04-04T13:56:00.304574Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:56:04.572312Z","iopub.execute_input":"2024-04-04T13:56:04.572721Z","iopub.status.idle":"2024-04-04T13:56:05.915221Z","shell.execute_reply.started":"2024-04-04T13:56:04.572672Z","shell.execute_reply":"2024-04-04T13:56:05.914220Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"wandb.login(key='cd7a6c2259e8886dc269bbf6f0f9e55089d3beeb')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:56:09.764632Z","iopub.execute_input":"2024-04-04T13:56:09.765519Z","iopub.status.idle":"2024-04-04T13:56:11.746046Z","shell.execute_reply.started":"2024-04-04T13:56:09.765490Z","shell.execute_reply":"2024-04-04T13:56:11.745161Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'random',\n    'name' : 'sweep test6',\n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'kernel_size':{\n            'values': [[3,3,3,3,3], [3,5,5,7,7], [7,7,5,5,3]]\n        },\n        'dropout': {\n            'values': [0.2, 0.4]\n        },\n        'activation': {\n            'values': ['ReLU']#, 'gelu', 'silu', 'mish']\n        },\n        'batch_norm':{\n            'values': ['true','false']\n        },\n        'filt_org':{\n            'values': [[32,32,32,32,32],[128,128,64,64,32],[32,64,128,256,512]]\n        },\n        'data_augment': {\n            'values': ['true','false']\n        },\n        'num_dense':{\n            'values': [128, 256]\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep=sweep_config, project='Deep_Learning_Assignment2')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:56:16.326411Z","iopub.execute_input":"2024-04-04T13:56:16.326941Z","iopub.status.idle":"2024-04-04T13:56:16.602140Z","shell.execute_reply.started":"2024-04-04T13:56:16.326910Z","shell.execute_reply":"2024-04-04T13:56:16.601216Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Create sweep with ID: frc1gocm\nSweep URL: https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm\n","output_type":"stream"}]},{"cell_type":"code","source":"def main():\n    '''\n    WandB calls main function each time with differnet combination.\n\n    We can retrive the same and use the same values for our hypermeters.\n\n    '''\n\n\n    with wandb.init(entity = 'prabhat-kumar') as run:\n\n        run_name=\"-act_\"+wandb.config.activation+\"-ks\"+str(wandb.config.kernel_size)+'-da'+wandb.config.data_augment+'-nd'+str(wandb.config.num_dense)\n        wandb.run.name=run_name\n#         actv = get_activation(wandb.config.activation)\n        model = FlexibleCNN(num_classes=10, in_channels=3, conv_filters=wandb.config.filt_org, \n                 kernel_sizes=wandb.config.kernel_size, pool_sizes=[2, 2, 2, 2, 2], \n                 dense_units=wandb.config.num_dense, activation=wandb.config.activation).to(device)\n        \n        \n        # Loss and optimizer\n        criterion = nn.CrossEntropyLoss()\n        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n# Training loop\n        for epoch in range(num_epochs):\n            # Train the model\n            model.train()\n            for images, labels in train_loader:\n                \n                images = images.to(device)\n                labels = labels.to(device)\n        \n                # Forward pass\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n        \n                # Backward and optimize\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n    \n            # Validate the model\n            model.eval()\n            with torch.no_grad():\n                correct = 0\n                total = 0\n                for images, labels in val_loader:\n                    \n                    images = images.to(device)\n                    labels = labels.to(device)\n            \n                    # Forward pass\n                    outputs = model(images)\n                    _, predicted = torch.max(outputs, 1)\n            \n                    # Compute accuracy\n                    total += labels.size(0)\n                    correct += (predicted == labels).sum().item()\n            \n        \n                val_accuracy = 100 * correct / total\n                print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')\n                wandb.log({'validation_accuracy':val_accuracy})\n    \n\n        print('Finished Training')\n\n        '''\n        if wandb.config.optimizer == 'nesterov':\n          model.train_nag(x_train, y_train, wandb.config.learning_rate, wandb.config.epochs, wandb.config.batch_size)\n        if wandb.config.optimizer == 'momentum':\n          model.train_momentum(x_train, y_train, wandb.config.learning_rate, wandb.config.epochs, wandb.config.batch_size)\n        if wandb.config.optimizer == 'sgd':\n          model.train_sgd(x_train, y_train, wandb.config.learning_rate, wandb.config.epochs, wandb.config.batch_size)\n        if wandb.config.optimizer == 'adam':\n          model.train_adam(x_train, y_train, wandb.config.learning_rate, wandb.config.epochs, wandb.config.batch_size)\n        if wandb.config.optimizer == 'rmsprop':\n          model.train_rmsprop(x_train, y_train, wandb.config.learning_rate, wandb.config.epochs, wandb.config.batch_size)\n        if wandb.config.optimizer == 'nadam':\n          model.train_nadam(x_train, y_train, wandb.config.learning_rate, wandb.config.epochs, wandb.config.batch_size)'''\n        \n        \n\nwandb.agent(sweep_id, function=main,count=2) # calls main function for count number of times.\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:56:21.624591Z","iopub.execute_input":"2024-04-04T13:56:21.625261Z","iopub.status.idle":"2024-04-04T14:07:30.176604Z","shell.execute_reply.started":"2024-04-04T13:56:21.625229Z","shell.execute_reply":"2024-04-04T14:07:30.175773Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kc7yqcmt with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: false\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilt_org: [32, 32, 32, 32, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: [3, 3, 3, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprabhat-kumar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240404_135623-kc7yqcmt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/kc7yqcmt' target=\"_blank\">fearless-sweep-1</a></strong> to <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/kc7yqcmt' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/kc7yqcmt</a>"},"metadata":{}},{"name":"stdout","text":"5.0\nEpoch [1/2], Validation Accuracy: 9.70%\nEpoch [2/2], Validation Accuracy: 11.20%\nFinished Training\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.032 MB uploaded\\r'), FloatProgress(value=0.043270373010216204, max=1…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_accuracy</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_accuracy</td><td>11.2</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fearless-sweep-1</strong> at: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/kc7yqcmt' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/kc7yqcmt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240404_135623-kc7yqcmt/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8sm6hlzf with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: false\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilt_org: [128, 128, 64, 64, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: [7, 7, 5, 5, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240404_140245-8sm6hlzf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/8sm6hlzf' target=\"_blank\">effortless-sweep-2</a></strong> to <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/sweeps/frc1gocm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/8sm6hlzf' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/8sm6hlzf</a>"},"metadata":{}},{"name":"stdout","text":"3.0\nEpoch [1/2], Validation Accuracy: 9.65%\nEpoch [2/2], Validation Accuracy: 9.65%\nFinished Training\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation_accuracy</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation_accuracy</td><td>9.65</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">effortless-sweep-2</strong> at: <a href='https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/8sm6hlzf' target=\"_blank\">https://wandb.ai/prabhat-kumar/Deep_Learning_Assignment2/runs/8sm6hlzf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240404_140245-8sm6hlzf/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}